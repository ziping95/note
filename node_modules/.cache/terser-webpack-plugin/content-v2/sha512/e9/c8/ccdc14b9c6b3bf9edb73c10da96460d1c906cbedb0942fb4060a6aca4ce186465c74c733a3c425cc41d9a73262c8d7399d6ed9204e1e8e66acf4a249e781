{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{211:function(t,s,a){t.exports=a.p+\"assets/img/map-extends.a6077ca6.png\"},212:function(t,s,a){t.exports=a.p+\"assets/img/red-black-tree.971fe84e.png\"},248:function(t,s,a){\"use strict\";a.r(s);var n=a(0),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[n(\"h1\",{attrs:{id:\"集合\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#集合\"}},[t._v(\"#\")]),t._v(\" 集合\")]),t._v(\" \"),n(\"h2\",{attrs:{id:\"map\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#map\"}},[t._v(\"#\")]),t._v(\" Map\")]),t._v(\" \"),n(\"p\",[t._v(\"Java中，一般耳熟能详的Map通常有这么几类（\"),n(\"code\",[t._v(\"HashMap\")]),t._v(\"、\"),n(\"code\",[t._v(\"Hashtable\")]),t._v(\"、\"),n(\"code\",[t._v(\"LinkedHashMap\")]),t._v(\"、\"),n(\"code\",[t._v(\"TreeMap\")]),t._v(\"）\")]),t._v(\" \"),n(\"p\",[t._v(\"他们之间的关系如下图所示\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(211),alt:\"\"}}),t._v(\"\\n这几类Map的特点\")]),t._v(\" \"),n(\"ul\",[n(\"li\",[n(\"code\",[t._v(\"HashMap\")]),t._v(\" 用的最多，允许一个key为\"),n(\"code\",[t._v(\"null\")]),t._v(\"，无序，非线程安全，在需要线程安全的场景下需要使用\"),n(\"code\",[t._v(\"Collections\")]),t._v(\"的\"),n(\"code\",[t._v(\"synchronizedMap\")]),t._v(\"方法或者\"),n(\"code\",[t._v(\"ConcurrentHashMap\")]),t._v(\"类\")]),t._v(\" \"),n(\"li\",[n(\"code\",[t._v(\"ConcurrentHashMap\")]),t._v(\" 线程安全，支持高并发，高吞吐量的map，内部实现采用分段锁技术\")]),t._v(\" \"),n(\"li\",[n(\"code\",[t._v(\"LinkedHashMap\")]),t._v(\"有序的Map，是\"),n(\"code\",[t._v(\"HashMap\")]),t._v(\"的一个子类，记录了插入的顺序，在使用\"),n(\"code\",[t._v(\"Iterator\")]),t._v(\"遍历时，会按照插入顺序进行输出\")]),t._v(\" \"),n(\"li\",[n(\"code\",[t._v(\"TreeMap\")]),t._v(\" 实现了\"),n(\"code\",[t._v(\"SortedMap\")]),t._v(\"接口，也是有序的，默认按照字典序排序，也可以自定义比较器进行排序\")]),t._v(\" \"),n(\"li\",[n(\"code\",[t._v(\"Hashtable\")]),t._v(\" 被弃用的类，功能和\"),n(\"code\",[t._v(\"HashMap\")]),t._v(\"相似，线程安全，但性能比较差，因为同一时间只有一个线程可以执行写操作，没有遵循驼峰命名\")])]),t._v(\" \"),n(\"p\",[t._v(\"这里就重点总结HashMap相关的内容\")]),t._v(\" \"),n(\"h3\",{attrs:{id:\"hashmap\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#hashmap\"}},[t._v(\"#\")]),t._v(\" HashMap\")]),t._v(\" \"),n(\"p\",[n(\"code\",[t._v(\"HashMap\")]),t._v(\"在\"),n(\"code\",[t._v(\"JDK7\")]),t._v(\"中仅仅是数组+链表，而在\"),n(\"code\",[t._v(\"JDK8\")]),t._v(\"中的存储结构优化为了数组+链表+红黑树\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(212),alt:\"\"}}),t._v(\"\\n这样做的目的是如果在\"),n(\"code\",[t._v(\"key\")]),t._v(\"很多的情况下，大量的数据由于哈希碰撞，聚集在同一个下标的元素上，这时链表的查询效率会退化成O(n)\")]),t._v(\" \"),n(\"p\",[n(\"code\",[t._v(\"HashMap\")]),t._v(\"存储数据时，是先计算\"),n(\"code\",[t._v(\"key\")]),t._v(\"的哈希值，然后和数组长度-1相与（在\"),n(\"code\",[t._v(\"JDK7\")]),t._v(\"中是进行取模运算）得到的值必定为数组中某一个下标的值，因此将该\"),n(\"code\",[t._v(\"key\")]),t._v(\"放入这个数组所对应的链表中\")]),t._v(\" \"),n(\"p\",[t._v(\"这里用\"),n(\"code\",[t._v(\"JDK8\")]),t._v(\"举例，看一下\"),n(\"code\",[t._v(\"put\")]),t._v(\"方法时是如何处理的，在\"),n(\"code\",[t._v(\"put\")]),t._v(\"方法中，最终调用了\"),n(\"code\",[t._v(\"putVal\")]),t._v(\"方法\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"final\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"putVal\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),t._v(\" value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"boolean\")]),t._v(\" onlyIfAbsent\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"boolean\")]),t._v(\" evict\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" n\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" i\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 对数组初始化，默认数组初始化长度为16\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tab \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"||\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"n \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"length\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n        n \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tab \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"resize\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"length\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Hash值和数组长度减一相与后，判断对应下标的数组元素中是否为空，如果为空则直接新建一个节点放入数组中\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"p \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"n \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\" hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n        tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"newNode\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),t._v(\" k\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果对应下标元素中已经存在节点，则判断这个节点中的key和当前key是否一致\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果一致，则把旧节点赋予e，后续直接对节点e的value进行覆盖操作即可\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hash \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" hash \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&&\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"k \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" key \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"||\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"key \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&&\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"equals\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"k\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n            e \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断当前链表是否已经转换为红黑树，如果是，则进行红黑树插入值处理\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"p \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"instanceof\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TreeNode\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n            e \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TreeNode\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"putTreeVal\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"this\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 当链表中的头元素中的key不匹配时，进入到这里，遍历链表\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"for\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" binCount \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),t._v(\"binCount\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断当前链表节点的next元素是否为空，如果为空，则直接新建节点放入next即可\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"next\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                    p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"next \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"newNode\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断链表长度是否超过8，若是则将链表转换为红黑树\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 注意在treeifyBin方法中又判断了数组长度是否大于64，若不大于仅仅做一次扩容\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"binCount \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\">=\")]),t._v(\" TREEIFY_THRESHOLD \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// -1 for 1st\")]),t._v(\"\\n                        \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"treeifyBin\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"break\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 若next节点不为空，则判断next节点的key是否和当前key相同\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果相同，退出循环，后续进行覆盖value操作\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hash \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" hash \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&&\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"k \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" key \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"||\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"key \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&&\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"equals\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"k\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"break\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果next节点的key不一致，则将next节点赋予当前节点，继续遍历\")]),t._v(\"\\n                p \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果通过以上逻辑发现有相同的key，则在这里进行value值的覆盖，并返回旧数据\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// existing mapping for key\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),t._v(\" oldValue \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!\")]),t._v(\"onlyIfAbsent \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"||\")]),t._v(\" oldValue \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n                e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"value \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"afterNodeAccess\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" oldValue\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),t._v(\"modCount\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断数组元素数量是否超过长度*负载因子，是否需要扩容\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),t._v(\"size \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\">\")]),t._v(\" threshold\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"resize\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"afterNodeInsertion\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"evict\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),n(\"p\",[t._v(\"从以上代码中可以看出，在\"),n(\"code\",[t._v(\"JD8\")]),t._v(\"中插入数据时采用的是尾插法，同时在代码中我们可以看到\"),n(\"code\",[t._v(\"modCount\")]),t._v(\"属性，这个属性记录的是当前容器对象被修改的次数，用于快速失败机制，所有非线程安全地集合类都存在该属性\")]),t._v(\" \"),n(\"div\",{staticClass:\"custom-block tip\"},[n(\"p\",{staticClass:\"custom-block-title\"},[t._v(\"Fail-Fast 策略\")]),t._v(\" \"),n(\"p\",[t._v(\"我们知道 java.util.HashMap 不是线程安全的，因此如果在使用迭代器的过程中有其他线程修改了map，那么将抛出ConcurrentModificationException，这就是所谓fail-fast策略。\")]),t._v(\" \"),n(\"p\",[t._v(\"这一策略在源码中的实现是通过 modCount 属性。modCount 顾名思义就是修改次数，对HashMap 内容的修改都将增加这个值。\\n在迭代器初始化过程中会将这个值赋给迭代器的 expectedModCount。\\n在迭代过程中，不断判断 modCount 跟 expectedModCount 是否相等，如果不相等就表示已经有其他线程修改了 Map，立刻抛出 ConcurrentModificationException 异常。\\n注意， modCount 声明为 volatile，以保证线程之间修改的可见性。\")])]),t._v(\" \"),n(\"p\",[t._v(\"上面的代码我可以看到在数组长度达到阈值的时候，会对数组进行扩容，并依据hash重新分配链表位置，下面我们看一下负责数组扩容的方法\"),n(\"code\",[t._v(\"resize()\")])]),t._v(\" \"),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"final\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"resize\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" oldTab \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 这里判断MAP是否经历过初始化\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" oldCap \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"oldTab \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"?\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" oldTab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"length\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 下次扩容时的元素上限，如果在初始化时指定容量，实际修改的是threshold\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 在后面会将threshold赋值给newCap，并且依据newCap重新计算threshold\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" oldThr \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" threshold\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" newCap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" newThr \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"oldCap \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\">\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断旧数组长度是否大于2的30次方，如果大于则不进行扩容，仅仅是将threshold调整为int的最大值，后面介绍为什么是2的30次方\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"oldCap \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\">=\")]),t._v(\" MAXIMUM_CAPACITY\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            threshold \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Integer\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"MAX_VALUE\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" oldTab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断数组扩容后是否小于2^30且是否大于等于默认容量\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 未看懂为什么必须大于等于默认容量\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"newCap \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" oldCap \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<<\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\" MAXIMUM_CAPACITY \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"\\n                 oldCap \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" DEFAULT_INITIAL_CAPACITY\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 全满足后进行扩容一倍容量\")]),t._v(\"\\n            newThr \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" oldThr \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<<\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果初始化指定容量时，在这里会依据初始容量进行扩容\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"oldThr \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\">\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n        newCap \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" oldThr\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"               \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// zero initial threshold signifies using defaults\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 对未指定初始容量的map使用默认容量和阈值\")]),t._v(\"\\n        newCap \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" DEFAULT_INITIAL_CAPACITY\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        newThr \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"DEFAULT_LOAD_FACTOR \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),t._v(\" DEFAULT_INITIAL_CAPACITY\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 这里计算指定初始容量的Map的阈值\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"newThr \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"float\")]),t._v(\" ft \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"float\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"newCap \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"*\")]),t._v(\" loadFactor\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        newThr \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"newCap \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<\")]),t._v(\" MAXIMUM_CAPACITY \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&&\")]),t._v(\" ft \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"float\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"MAXIMUM_CAPACITY \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"?\")]),t._v(\"\\n                  \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"ft \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Integer\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"MAX_VALUE\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    threshold \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" newThr\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token annotation punctuation\"}},[t._v(\"@SuppressWarnings\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"rawtypes\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"unchecked\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" newTab \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"newCap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    table \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" newTab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"oldTab \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 遍历旧数组，重新计算元素在新数组的下标\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"for\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" j \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" j \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<\")]),t._v(\" oldCap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),t._v(\"j\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断原数组中当前下标是否有元素\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" oldTab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"j\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                oldTab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"j\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断链表上是否还有其他节点，如果没有就直接计算新数组中的下标\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"next \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n                    newTab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hash \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"newCap \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断链表是否转换为红黑树（暂时未看）\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"instanceof\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TreeNode\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TreeNode\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"split\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"this\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" newTab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" j\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" oldCap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 假设从16扩容到32，那么经过重新计算得到的下标依旧在0-15中则成为低位，反正称为高位\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 用来保存低位的头元素和尾元素\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" loHead \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" loTail \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 用来保存高位的头元素和尾元素\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" hiHead \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" hiTail \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" next\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"do\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 保存当前节点的next节点引用\")]),t._v(\"\\n                        next \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"next\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断新下标是否为低位\")]),t._v(\"\\n                        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hash \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\" oldCap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                            \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断当前是否有头节点，如果没有，则把当前节点保存为头节点，否则将当前节点放入链表的尾部\")]),t._v(\"\\n                            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"loTail \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n                                loHead \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\"\\n                                loTail\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"next \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                            \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 更新链表尾部指向\")]),t._v(\"\\n                            loTail \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n                        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                            \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 高位处理逻辑同低位\")]),t._v(\"\\n                            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"hiTail \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n                                hiHead \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\"\\n                                hiTail\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"next \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                            hiTail \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断当前链表是否遍历完成\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" next\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 将低位的新链表放入新数组中\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"loTail \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                        loTail\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"next \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                        newTab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"j\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" loHead\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 将高位的新链表放入当前下标 + 旧数组长度位置\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"hiTail \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                        hiTail\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"next \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                        newTab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"j \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" oldCap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" hiHead\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" newTab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),n(\"p\",[t._v(\"在代码中这个判断为什么只需要判断是否等于0\"),n(\"code\",[t._v(\"if((e.hash & oldCap) == 0)\")]),t._v(\"，这是因为相与之后的结果只能是0或者是旧数组的长度\")]),t._v(\" \"),n(\"p\",[t._v(\"例如旧数组长度是16，有两个hash值分别是后八位分别是\"),n(\"code\",[t._v(\"1111 1111\")]),t._v(\"和\"),n(\"code\",[t._v(\"1110 1111\")]),t._v(\"，那么相与的结果分别是16和0，因此结果只取决于hash值中倒数第五的值是否为1，因此在本例子中，结果只能是0或者16\")])])}),[],!1,null,null,null);s.default=e.exports}}]);","extractedComments":[]}