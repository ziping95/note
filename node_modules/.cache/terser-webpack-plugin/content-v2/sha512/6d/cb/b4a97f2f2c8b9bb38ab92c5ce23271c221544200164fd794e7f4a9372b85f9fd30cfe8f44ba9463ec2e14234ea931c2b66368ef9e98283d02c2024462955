{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{206:function(t,s,a){t.exports=a.p+\"assets/img/map-extends.a6077ca6.png\"},207:function(t,s,a){t.exports=a.p+\"assets/img/red-black-tree.971fe84e.png\"},244:function(t,s,a){\"use strict\";a.r(s);var n=a(0),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[n(\"h1\",{attrs:{id:\"集合\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#集合\"}},[t._v(\"#\")]),t._v(\" 集合\")]),t._v(\" \"),n(\"h2\",{attrs:{id:\"map\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#map\"}},[t._v(\"#\")]),t._v(\" Map\")]),t._v(\" \"),n(\"p\",[t._v(\"Java中，一般耳熟能详的Map通常有这么几类（\"),n(\"code\",[t._v(\"HashMap\")]),t._v(\"、\"),n(\"code\",[t._v(\"Hashtable\")]),t._v(\"、\"),n(\"code\",[t._v(\"LinkedHashMap\")]),t._v(\"、\"),n(\"code\",[t._v(\"TreeMap\")]),t._v(\"）\")]),t._v(\" \"),n(\"p\",[t._v(\"他们之间的关系如下图所示\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(206),alt:\"\"}}),t._v(\"\\n这几类Map的特点\")]),t._v(\" \"),n(\"ul\",[n(\"li\",[n(\"code\",[t._v(\"HashMap\")]),t._v(\" 用的最多，允许一个key为\"),n(\"code\",[t._v(\"null\")]),t._v(\"，无序，非线程安全，在需要线程安全的场景下需要使用\"),n(\"code\",[t._v(\"Collections\")]),t._v(\"的\"),n(\"code\",[t._v(\"synchronizedMap\")]),t._v(\"方法或者\"),n(\"code\",[t._v(\"ConcurrentHashMap\")]),t._v(\"类\")]),t._v(\" \"),n(\"li\",[n(\"code\",[t._v(\"ConcurrentHashMap\")]),t._v(\" 线程安全，支持高并发，高吞吐量的map，内部实现采用分段锁技术\")]),t._v(\" \"),n(\"li\",[n(\"code\",[t._v(\"LinkedHashMap\")]),t._v(\"有序的Map，是\"),n(\"code\",[t._v(\"HashMap\")]),t._v(\"的一个子类，记录了插入的顺序，在使用\"),n(\"code\",[t._v(\"Iterator\")]),t._v(\"遍历时，会按照插入顺序进行输出\")]),t._v(\" \"),n(\"li\",[n(\"code\",[t._v(\"TreeMap\")]),t._v(\" 实现了\"),n(\"code\",[t._v(\"SortedMap\")]),t._v(\"接口，也是有序的，默认按照字典序排序，也可以自定义比较器进行排序\")]),t._v(\" \"),n(\"li\",[n(\"code\",[t._v(\"Hashtable\")]),t._v(\" 被弃用的类，功能和\"),n(\"code\",[t._v(\"HashMap\")]),t._v(\"相似，线程安全，但性能比较差，因为同一时间只有一个线程可以执行写操作，没有遵循驼峰命名\")])]),t._v(\" \"),n(\"p\",[t._v(\"这里就重点总结HashMap相关的内容\")]),t._v(\" \"),n(\"h3\",{attrs:{id:\"hashmap-存储结构\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#hashmap-存储结构\"}},[t._v(\"#\")]),t._v(\" HashMap 存储结构\")]),t._v(\" \"),n(\"p\",[n(\"code\",[t._v(\"HashMap\")]),t._v(\"在\"),n(\"code\",[t._v(\"JDK7\")]),t._v(\"中仅仅是数组+链表，而在\"),n(\"code\",[t._v(\"JDK8\")]),t._v(\"中的存储结构优化为了数组+链表+红黑树\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(207),alt:\"\"}}),t._v(\"\\n这样做的目的是如果在\"),n(\"code\",[t._v(\"key\")]),t._v(\"很多的情况下，大量的数据由于哈希碰撞，聚集在同一个下标的元素上，这时链表的查询效率会退化成O(n)\")]),t._v(\" \"),n(\"p\",[n(\"code\",[t._v(\"HashMap\")]),t._v(\"存储数据时，是先计算\"),n(\"code\",[t._v(\"key\")]),t._v(\"的哈希值，然后和数组长度-1相与（在\"),n(\"code\",[t._v(\"JDK7\")]),t._v(\"中是进行取模运算）得到的值必定为数组中某一个下标的值，因此将该\"),n(\"code\",[t._v(\"key\")]),t._v(\"放入这个数组所对应的链表中\")]),t._v(\" \"),n(\"p\",[t._v(\"这里用\"),n(\"code\",[t._v(\"JDK8\")]),t._v(\"举例，看一下\"),n(\"code\",[t._v(\"put\")]),t._v(\"方法时是如何处理的，在\"),n(\"code\",[t._v(\"put\")]),t._v(\"方法中，最终调用了\"),n(\"code\",[t._v(\"putVal\")]),t._v(\"方法\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"final\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"putVal\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),t._v(\" value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"boolean\")]),t._v(\" onlyIfAbsent\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"boolean\")]),t._v(\" evict\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" n\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" i\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 对数组初始化，默认数组初始化长度为16\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tab \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" table\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"||\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"n \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"length\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n        n \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tab \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"resize\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"length\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Hash值和数组长度减一相与后，判断对应下标的数组元素中是否为空，如果为空则直接新建一个节点放入数组中\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"p \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"n \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\" hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n        tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"newNode\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Node\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),t._v(\" k\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果对应下标元素中已经存在节点，则判断这个节点中的key和当前key是否一致\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果一致，则把旧节点赋予e，后续直接对节点e的value进行覆盖操作即可\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hash \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" hash \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&&\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"k \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" key \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"||\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"key \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&&\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"equals\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"k\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n            e \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断当前链表是否已经转换为红黑树，如果是，则进行红黑树插入值处理\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"p \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"instanceof\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TreeNode\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n            e \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TreeNode\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"K\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"putTreeVal\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"this\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 当链表中的头元素中的key不匹配时，进入到这里，遍历链表\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"for\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" binCount \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),t._v(\"binCount\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断当前链表节点的next元素是否为空，如果为空，则直接新建节点放入next即可\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"next\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n                    p\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"next \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"newNode\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断链表长度是否超过8，若是则将链表转换为红黑树\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"binCount \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\">=\")]),t._v(\" TREEIFY_THRESHOLD \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// -1 for 1st\")]),t._v(\"\\n                        \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"treeifyBin\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tab\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" hash\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"break\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 若next节点不为空，则判断next节点的key是否和当前key相同\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果相同，退出循环，后续进行覆盖value操作\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"hash \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" hash \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&&\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"k \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" key \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"||\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"key \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&&\")]),t._v(\" key\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"equals\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"k\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n                    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"break\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n                \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果next节点的key不一致，则将next节点赋予当前节点，继续遍历\")]),t._v(\"\\n                p \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 如果通过以上逻辑发现有相同的key，则在这里进行value值的覆盖，并返回旧数据\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// existing mapping for key\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"V\")]),t._v(\" oldValue \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"!\")]),t._v(\"onlyIfAbsent \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"||\")]),t._v(\" oldValue \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n                e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"value \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" value\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"afterNodeAccess\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" oldValue\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),t._v(\"modCount\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 判断数组元素数量是否超过长度*负载因子，是否需要扩容\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),t._v(\"size \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\">\")]),t._v(\" threshold\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"resize\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"afterNodeInsertion\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"evict\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),n(\"p\",[t._v(\"从以上代码中可以看出，在\"),n(\"code\",[t._v(\"JD8\")]),t._v(\"中插入数据时采用的是尾插法，同时在代码中我们可以看到\"),n(\"code\",[t._v(\"modCount\")]),t._v(\"属性，这个属性记录的是当前容器对象被修改的次数，用于快速失败机制，所有非线程安全地集合类都存在该属性\")]),t._v(\" \"),n(\"div\",{staticClass:\"custom-block tip\"},[n(\"p\",{staticClass:\"custom-block-title\"},[t._v(\"Fail-Fast 策略\")]),t._v(\" \"),n(\"p\",[t._v(\"我们知道 java.util.HashMap 不是线程安全的，因此如果在使用迭代器的过程中有其他线程修改了map，那么将抛出ConcurrentModificationException，这就是所谓fail-fast策略。\")]),t._v(\" \"),n(\"p\",[t._v(\"这一策略在源码中的实现是通过 modCount 属性。modCount 顾名思义就是修改次数，对HashMap 内容的修改都将增加这个值。\\n在迭代器初始化过程中会将这个值赋给迭代器的 expectedModCount。\\n在迭代过程中，不断判断 modCount 跟 expectedModCount 是否相等，如果不相等就表示已经有其他线程修改了 Map，立刻抛出 ConcurrentModificationException 异常。\\n注意， modCount 声明为 volatile，以保证线程之间修改的可见性。\")])])])}),[],!1,null,null,null);s.default=e.exports}}]);","extractedComments":[]}